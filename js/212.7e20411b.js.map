{"version":3,"file":"js/212.7e20411b.js","mappings":"gSAQO,MAAMA,UAA4B,IACrC,cAAOC,GACH,MAAO,qBACX,CACA,aAAIC,GACA,MAAO,CAACC,KAAKC,YAAaD,KAAKE,SAASH,WAAWI,QAAQC,GAAQA,IAAQJ,KAAKK,sBACpF,CACA,cAAIC,GACA,OAAON,KAAKE,SAASI,UACzB,CACA,WAAAC,CAAYC,GACRC,MAAMD,GACNE,OAAOC,eAAeX,KAAM,WAAY,CACpCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,WAAO,IAEXL,OAAOC,eAAeX,KAAM,WAAY,CACpCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,oBAEXL,OAAOC,eAAeX,KAAM,uBAAwB,CAChDY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,YAEXf,KAAKE,SAAWM,EAAON,SACvBF,KAAKK,qBACDG,EAAOH,sBAAwBL,KAAKK,qBACxCL,KAAKC,SAAWO,EAAOP,UAAYD,KAAKC,QAC5C,CAEA,WAAAe,CAAYC,GACR,KAAMjB,KAAKC,YAAYgB,GACnB,MAAM,IAAIC,MAAM,gBAAgBlB,KAAKC,uBAEzC,MAAQ,CAACD,KAAKC,UAAWkB,KAASC,GAASH,EACrCI,EAAQF,EAAKG,KAAI,EAAGC,iBAAkBA,IACtCC,EAAOH,EAAMI,KAAK,QACxB,MAAO,IACAL,EACH,CAACpB,KAAKK,sBAAuBmB,EAErC,CAEA,WAAME,CAAMT,EAAQU,GAChB,MAAMC,QAAe5B,KAAKE,SAAS2B,KAAK7B,KAAKgB,YAAYC,GAASU,GAAYG,SAAS,sBACvF,OAAOF,CACX,CACA,UAAAG,GACI,MAAO,uBACX,CACA,wBAAaC,CAAYC,GACrB,IAAKA,EAAKC,UACN,MAAM,IAAIhB,MAAM,qBAEpB,OAAO,IAAIrB,EAAoB,CAC3BK,eAAgB,EAAAiC,SAASH,YAAYC,EAAKC,YAElD,CACA,SAAAE,GACI,MAAO,CACHC,MAAOrC,KAAK+B,aACZG,UAAWlC,KAAKE,SAASkC,YAEjC,EAOG,MAAME,UAAgC,IACzC,cAAOxC,GACH,MAAO,yBACX,CACA,aAAIC,GACA,MAAO,CAACC,KAAKC,YAAaD,KAAKuC,qBAAqBxC,UACxD,CACA,cAAIO,GACA,OAAON,KAAKuC,qBAAqBjC,UACrC,CACA,WAAAC,CAAYC,GACRC,MAAMD,GACNE,OAAOC,eAAeX,KAAM,WAAY,CACpCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,WAAO,IAEXL,OAAOC,eAAeX,KAAM,WAAY,CACpCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,oBAEXL,OAAOC,eAAeX,KAAM,uBAAwB,CAChDY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,YAEXL,OAAOC,eAAeX,KAAM,0BAA2B,CACnDY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,OAAO,IAEXL,OAAOC,eAAeX,KAAM,YAAa,CACrCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,MAEXL,OAAOC,eAAeX,KAAM,gBAAiB,CACzCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,KAEXL,OAAOC,eAAeX,KAAM,gBAAiB,CACzCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,OAAO,IAEXL,OAAOC,eAAeX,KAAM,uBAAwB,CAChDY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,WAAO,IAEXf,KAAKE,SAAWM,EAAON,SACvBF,KAAKuC,qBAAuB/B,EAAO+B,qBACnCvC,KAAKK,qBACDG,EAAOH,sBAAwBL,KAAKK,qBACxCL,KAAKwC,cAAgBhC,EAAOgC,eAAiBxC,KAAKwC,cAClDxC,KAAKC,SAAWO,EAAOP,UAAYD,KAAKC,SACxCD,KAAKyC,UAAYjC,EAAOiC,WAAazC,KAAKyC,UAC1CzC,KAAK0C,cAAgBlC,EAAOkC,eAAiB1C,KAAK0C,cAClD1C,KAAK2C,wBAA0BnC,EAAOmC,0BAA2B,CACrE,CAEA,WAAMjB,CAAMT,EAAQU,GAChB,KAAM3B,KAAKC,YAAYgB,GACnB,MAAM,IAAIC,MAAM,gBAAgBlB,KAAKC,uBAEzC,MAAQ,CAACD,KAAKC,UAAWkB,KAASC,GAASH,EAC3C,IAAI2B,EAAczB,EACd0B,EAAoB,GAExB,IAAK,IAAIC,EAAI,EAAGA,EAAI9C,KAAK0C,cAAeI,GAAK,EAAG,CAC5C,MAAMC,EAASH,EAAYtB,KAAK0B,IAAM,CAClC,CAAChD,KAAKK,sBAAuB2C,EAAEzB,eAC5BH,MAED6B,EAAuB,IAANH,IAAY9C,KAAKwC,cACxC,GAAIS,EAAgB,CAEhB,MAAMC,QAAkBlD,KAAKuC,qBAAqBrC,SAASiD,OAAOC,OAAOpD,KAAKuC,qBAAqBvB,YAAY,CAC3G,CAAChB,KAAKuC,qBAAqBtC,UAAW2C,KACnCxB,KAEDiC,QAAerD,KAAKuC,qBAAqBrC,SAASoD,cAAcJ,GAChEK,EAAmBF,EAASrD,KAAKyC,UAGvC,GAAIc,EACA,KAER,CACA,MAAMC,QAAgBxD,KAAKE,SAASuD,MAAMV,EAG1CpB,EACM+B,MAAMC,KAAK,CAAEN,OAAQN,EAAOM,SAAU,CAACO,EAAGd,IAAMnB,EAAWG,SAAS,OAAOgB,EAAI,YAC/Ee,IACA,UAAEC,GAAc9D,KAAKE,SAEvBF,KAAK2C,0BACLE,EAAoBA,EAAkBkB,OAAOP,EAAQlC,KAAK0C,GAAMA,EAAEF,OAEtElB,EAAcY,EAAQlC,KAAK0C,IAAM,CAC7BzC,YAAayC,EAAEF,GACfG,SAAU,CAAC,KAEnB,CAGA,MAAMC,EAAY,CACd,CAAClE,KAAKuC,qBAAqBtC,UAAW2C,KACnCxB,GAEDQ,QAAe5B,KAAKuC,qBAAqBV,KAAKqC,EAAWvC,GAAYG,SAAS,sBAEpF,OAAI9B,KAAK2C,wBACE,IAAKf,EAAQiB,qBAEjBjB,CACX,CACA,UAAAG,GACI,MAAO,4BACX,CACA,wBAAaC,CAAYC,GACrB,IAAKA,EAAKC,UACN,MAAM,IAAIhB,MAAM,qBAEpB,IAAKe,EAAKkC,uBACN,MAAM,IAAIjD,MAAM,kCAEpB,OAAO,IAAIoB,EAAwB,CAC/BpC,eAAgB,EAAAiC,SAASH,YAAYC,EAAKC,WAC1CK,2BAA4B1C,EAAoBmC,YAAYC,EAAKkC,yBAEzE,CACA,SAAA/B,GACI,MAAO,CACHC,MAAOrC,KAAK+B,aACZG,UAAWlC,KAAKE,SAASkC,YACzB+B,uBAAwBnE,KAAKuC,qBAAqBH,YAE1D,EAOG,MAAMgC,UAA6B,IACtC,cAAOtE,GACH,MAAO,sBACX,CACA,yBAAIuE,GACA,OAAO,IAAI,KAAe,CACtBC,eAAgB,CAAC,gBACjBC,SAAU,kBAElB,CACA,aAAIxE,GACA,MAAO,IACA,IAAIyE,IAAI,CACPxE,KAAKC,YACFD,KAAKE,SAASH,aACdC,KAAKyE,eAAe1E,aAE7BI,QAAQC,GAAQA,IAAQJ,KAAKK,sBAAwBD,IAAQJ,KAAK0E,qBACxE,CACA,cAAIpE,GACA,MAAO,CAACN,KAAK8D,UACjB,CACA,WAAAvD,CAAYC,GACRC,MAAMD,GACNE,OAAOC,eAAeX,KAAM,WAAY,CACpCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,WAAO,IAEXL,OAAOC,eAAeX,KAAM,WAAY,CACpCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,oBAEXL,OAAOC,eAAeX,KAAM,YAAa,CACrCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,gBAEXL,OAAOC,eAAeX,KAAM,uBAAwB,CAChDY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,YAEXL,OAAOC,eAAeX,KAAM,sBAAuB,CAC/CY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,oBAEXL,OAAOC,eAAeX,KAAM,iBAAkB,CAC1CY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,WAAO,IAEXL,OAAOC,eAAeX,KAAM,iBAAkB,CAC1CY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAOf,KAAKqE,wBAEhBrE,KAAKE,SAAWM,EAAON,SACvBF,KAAKyE,eAAiBjE,EAAOiE,eAC7BzE,KAAKK,qBACDG,EAAOH,sBAAwBL,KAAKK,qBACxCL,KAAKC,SAAWO,EAAOP,UAAYD,KAAKC,SACxCD,KAAK8D,UAAYtD,EAAOsD,WAAa9D,KAAK8D,UAC1C9D,KAAK2E,eAAiBnE,EAAOmE,gBAAkB3E,KAAK2E,eACpD3E,KAAK0E,oBACDlE,EAAOkE,qBAAuB1E,KAAK0E,mBAC3C,CAEA,6BAAME,CAAwBC,EAAKzD,GAC/B,MAAM0D,EAAW,CACbC,aAAcF,EAAItD,eACfsD,EAAIZ,UAELe,EAAe,CAAC,EACtBhF,KAAK2E,eAAeL,eAAeW,SAASlE,IACxCiE,EAAajE,GAAS+D,EAAS/D,EAAM,IAEzC,MAAMmE,EAAa,CACf,CAAClF,KAAKK,4BAA6BL,KAAK2E,eAAevB,OAAO,IACvD4B,KAGLjC,EAAS,IAAKmC,KAAe9D,GACnC,OAAO2B,CACX,CAEA,4BAAMoC,CAAuBN,EAAKO,GAC9B,MAAMN,EAAW,CACbC,aAAcF,EAAItD,eACfsD,EAAIZ,UAELe,EAAe,CAAC,EACtBhF,KAAK2E,eAAeL,eAAeW,SAASlE,IACxCiE,EAAajE,GAAS+D,EAAS/D,EAAM,IAEzC,MAAMmE,EAAa,CACf,CAAClF,KAAKK,4BAA6BL,KAAK2E,eAAevB,OAAO,IACvD4B,KAGLjC,EAAS,CAAE,CAAC/C,KAAK0E,qBAAsBU,KAAQF,GACrD,OAAOnC,CACX,CAEA,WAAMrB,CAAMT,EAAQU,GAChB,KAAM3B,KAAKC,YAAYgB,GACnB,MAAM,IAAIC,MAAM,gBAAgBlB,KAAKC,uBAEzC,MAAQ,CAACD,KAAKC,UAAWkB,KAASC,GAASH,EACrC2B,EAAczB,EACdkE,QAAsBrF,KAAK4E,wBAAwBhC,EAAY,GAAIxB,GACzE,IAAIgE,QAAYpF,KAAKE,SAASoF,QAAQ,IAAKD,GAAiB1D,GAAYG,SAAS,WACjF,MAAMyD,EAAc,CAACH,GACrB,IAAK,IAAItC,EAAI,EAAGA,EAAIF,EAAYS,OAAQP,GAAK,EAAG,CAC5C,MAAM0C,QAAqBxF,KAAKmF,uBAAuBvC,EAAYE,GAAIsC,GACjErC,EAAS,IAAKyC,KAAiBpE,GACrCgE,QAAYpF,KAAKyE,eAAea,QAAQ,IAAKvC,GAAUpB,GAAYG,SAAS,WAC5EyD,EAAYE,KAAKL,EACrB,CACA,MAAO,CAAE,CAACpF,KAAK8D,WAAYsB,EAC/B,CACA,UAAArD,GACI,MAAO,wBACX,CACA,wBAAaC,CAAYC,GACrB,MAAMyD,EAAqBzD,EAAKC,UAChC,IAAKwD,EACD,MAAM,IAAIxE,MAAM,qBAEpB,MAAMyE,EAAgC1D,EAAK2D,iBAC3C,IAAKD,EACD,MAAM,IAAIzE,MAAM,4BAEpB,OAAO,IAAIkD,EAAqB,CAC5BlE,eAAgB,EAAAiC,SAASH,YAAY0D,GACrCjB,qBAAsB,EAAAtC,SAASH,YAAY2D,IAEnD,CACA,SAAAvD,GACI,MAAO,CACHC,MAAOrC,KAAK+B,aACZG,UAAWlC,KAAKE,SAASkC,YACzBwD,iBAAkB5F,KAAKyE,eAAerC,YAE9C,E,iICrYqC,ICAlC,MAAMyD,EAQT,oBAAMC,CAAeC,EAAKC,GACtB,MAAM7C,EAASnD,KAAKiG,UAAUF,GAC9B,OAAO5C,EAAO+C,QAAQF,GAASG,kBAAoB,CAAC,EACxD,EAOG,MAAMC,UAAkCP,EAC3C,WAAAtF,CAAY8F,EAAgBC,EAAe,IACvC7F,QACAC,OAAOC,eAAeX,KAAM,gBAAiB,CACzCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,WAAO,IAEXL,OAAOC,eAAeX,KAAM,eAAgB,CACxCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,WAAO,IAEXf,KAAKuG,cAAgBF,EACrBrG,KAAKsG,aAAeA,CACxB,CAOA,SAAAL,CAAUF,GACN,IAAK,MAAOS,EAAWrD,KAAWnD,KAAKsG,aACnC,GAAIE,EAAUT,GACV,OAAO5C,EAGf,OAAOnD,KAAKuG,aAChB,EAaG,SAASE,EAAYV,GACxB,MAA4B,oBAArBA,EAAIW,YACf,C,SCjEO,MAAMC,EAAkC,IAAI,KAAe,CAC9DpC,SAAU,2NACVD,eAAgB,CAAC,UAAW,cAE1BsC,EAAkB,+LAIlBC,EAAW,CACC,KAA4BC,aAAaF,GACzC,KAA2BE,aAAa,eAEpDC,EAA4B,KAAmBC,aAAaH,GACrDI,EAAmC,IAAIb,EAA0BO,EAAmB,CAAC,CAACF,EAAaM,KCSzG,SAASG,EAAiBnB,EAAKoB,EAAS,CAAC,GAC5C,MAAM,OAAEhE,EAAS8D,EAAmBhB,UAAUF,GAAI,QAAEqB,GAAYD,EAC1DjH,EAAW,IAAI,EAAAiC,SAAS,CAAEgB,SAAQ4C,MAAKqB,YACvCC,EAAQ,IAAI,EAAAxH,oBAAoB,CAAEK,WAAUkH,YAClD,OAAOC,CACX,CClBO,MAAMC,UAAwB,IACjC,cAAOxH,GACH,MAAO,iBACX,CACA,aAAIC,GACA,MAAO,CAACC,KAAKC,SACjB,CACA,cAAIK,GACA,OAAON,KAAKuH,sBAAsBjH,WAAWyD,OAAO/D,KAAKwH,sBAAwB,CAAC,mBAAqB,GAC3G,CACA,WAAAjH,CAAYC,GACRC,MAAMD,GACNE,OAAOC,eAAeX,KAAM,IAAK,CAC7BY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,IAEXL,OAAOC,eAAeX,KAAM,WAAY,CACpCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,MAAO,UAEXL,OAAOC,eAAeX,KAAM,cAAe,CACvCY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,WAAO,IAEXL,OAAOC,eAAeX,KAAM,wBAAyB,CACjDY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,WAAO,IAEXL,OAAOC,eAAeX,KAAM,wBAAyB,CACjDY,YAAY,EACZC,cAAc,EACdC,UAAU,EACVC,OAAO,IAEXf,KAAKyH,YAAcjH,EAAOiH,YAC1BzH,KAAKuH,sBAAwB/G,EAAO+G,sBACpCvH,KAAKC,SAAWO,EAAOP,UAAYD,KAAKC,SACxCD,KAAK0H,EAAIlH,EAAOkH,GAAK1H,KAAK0H,EAC1B1H,KAAKwH,sBACDhH,EAAOgH,uBAAyBxH,KAAKwH,qBAC7C,CAEA,WAAM9F,CAAMT,EAAQU,GAChB,KAAM3B,KAAKC,YAAYgB,GACnB,MAAM,IAAIC,MAAM,gBAAgBlB,KAAKC,uBAEzC,MAAM0H,EAAW1G,EAAOjB,KAAKC,UACvBkB,QAAanB,KAAKyH,YAAYG,iBAAiBD,EAAU3H,KAAK0H,EAAGzG,EAAOd,OAAQwB,GAAYG,SAAS,gBACrGiB,EAAS,CAAE4E,WAAUE,gBAAiB1G,GACtCS,QAAe5B,KAAKuH,sBAAsB1F,KAAKkB,EAAQpB,GAAYG,SAAS,sBAClF,OAAI9B,KAAKwH,sBACE,IACA5F,EACHkG,gBAAiB3G,GAGlBS,CACX,CACA,UAAAG,GACI,MAAO,cACX,CACA,wBAAaC,CAAYC,EAAMhB,GAC3B,KAAM,gBAAiBA,GACnB,MAAM,IAAIC,MAAM,gEAEpB,MAAM,YAAEuG,GAAgBxG,EACxB,IAAKgB,EAAK8F,wBACN,MAAM,IAAI7G,MAAM,wEAEpB,OAAO,IAAIoG,EAAgB,CACvBC,4BAA6B,IAAUvF,YAAYC,EAAK8F,yBACxDL,EAAGzF,EAAKyF,EACRD,eAER,CACA,SAAArF,GACI,MAAO,CACHC,MAAOrC,KAAK+B,aACZgG,wBAAyB/H,KAAKuH,sBAAsBnF,YACpDsF,EAAG1H,KAAK0H,EAEhB,CAUA,cAAOM,CAAQjC,EAAK0B,EAAazB,GAC7B,MAAMiC,EAAUf,EAAiBnB,GACjC,OAAO,IAAI/F,KAAK,CACZyH,cACAF,sBAAuBU,KACpBjC,GAEX,E","sources":["webpack://chatall/./node_modules/langchain/dist/chains/combine_docs_chain.js","webpack://chatall/./node_modules/@langchain/core/dist/example_selectors/base.js","webpack://chatall/./node_modules/@langchain/core/dist/example_selectors/conditional.js","webpack://chatall/./node_modules/langchain/dist/chains/question_answering/stuff_prompts.js","webpack://chatall/./node_modules/langchain/dist/chains/question_answering/load.js","webpack://chatall/./node_modules/langchain/dist/chains/vector_db_qa.js"],"sourcesContent":["import { PromptTemplate } from \"@langchain/core/prompts\";\nimport { BaseChain } from \"./base.js\";\nimport { LLMChain } from \"./llm_chain.js\";\n/**\n * Chain that combines documents by stuffing into context.\n * @augments BaseChain\n * @augments StuffDocumentsChainInput\n */\nexport class StuffDocumentsChain extends BaseChain {\n    static lc_name() {\n        return \"StuffDocumentsChain\";\n    }\n    get inputKeys() {\n        return [this.inputKey, ...this.llmChain.inputKeys].filter((key) => key !== this.documentVariableName);\n    }\n    get outputKeys() {\n        return this.llmChain.outputKeys;\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"llmChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"inputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"input_documents\"\n        });\n        Object.defineProperty(this, \"documentVariableName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"context\"\n        });\n        this.llmChain = fields.llmChain;\n        this.documentVariableName =\n            fields.documentVariableName ?? this.documentVariableName;\n        this.inputKey = fields.inputKey ?? this.inputKey;\n    }\n    /** @ignore */\n    _prepInputs(values) {\n        if (!(this.inputKey in values)) {\n            throw new Error(`Document key ${this.inputKey} not found.`);\n        }\n        const { [this.inputKey]: docs, ...rest } = values;\n        const texts = docs.map(({ pageContent }) => pageContent);\n        const text = texts.join(\"\\n\\n\");\n        return {\n            ...rest,\n            [this.documentVariableName]: text,\n        };\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        const result = await this.llmChain.call(this._prepInputs(values), runManager?.getChild(\"combine_documents\"));\n        return result;\n    }\n    _chainType() {\n        return \"stuff_documents_chain\";\n    }\n    static async deserialize(data) {\n        if (!data.llm_chain) {\n            throw new Error(\"Missing llm_chain\");\n        }\n        return new StuffDocumentsChain({\n            llmChain: await LLMChain.deserialize(data.llm_chain),\n        });\n    }\n    serialize() {\n        return {\n            _type: this._chainType(),\n            llm_chain: this.llmChain.serialize(),\n        };\n    }\n}\n/**\n * Combine documents by mapping a chain over them, then combining results.\n * @augments BaseChain\n * @augments StuffDocumentsChainInput\n */\nexport class MapReduceDocumentsChain extends BaseChain {\n    static lc_name() {\n        return \"MapReduceDocumentsChain\";\n    }\n    get inputKeys() {\n        return [this.inputKey, ...this.combineDocumentChain.inputKeys];\n    }\n    get outputKeys() {\n        return this.combineDocumentChain.outputKeys;\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"llmChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"inputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"input_documents\"\n        });\n        Object.defineProperty(this, \"documentVariableName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"context\"\n        });\n        Object.defineProperty(this, \"returnIntermediateSteps\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"maxTokens\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 3000\n        });\n        Object.defineProperty(this, \"maxIterations\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 10\n        });\n        Object.defineProperty(this, \"ensureMapStep\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"combineDocumentChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.llmChain = fields.llmChain;\n        this.combineDocumentChain = fields.combineDocumentChain;\n        this.documentVariableName =\n            fields.documentVariableName ?? this.documentVariableName;\n        this.ensureMapStep = fields.ensureMapStep ?? this.ensureMapStep;\n        this.inputKey = fields.inputKey ?? this.inputKey;\n        this.maxTokens = fields.maxTokens ?? this.maxTokens;\n        this.maxIterations = fields.maxIterations ?? this.maxIterations;\n        this.returnIntermediateSteps = fields.returnIntermediateSteps ?? false;\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        if (!(this.inputKey in values)) {\n            throw new Error(`Document key ${this.inputKey} not found.`);\n        }\n        const { [this.inputKey]: docs, ...rest } = values;\n        let currentDocs = docs;\n        let intermediateSteps = [];\n        // For each iteration, we'll use the `llmChain` to get a new result\n        for (let i = 0; i < this.maxIterations; i += 1) {\n            const inputs = currentDocs.map((d) => ({\n                [this.documentVariableName]: d.pageContent,\n                ...rest,\n            }));\n            const canSkipMapStep = i !== 0 || !this.ensureMapStep;\n            if (canSkipMapStep) {\n                // Calculate the total tokens required in the input\n                const formatted = await this.combineDocumentChain.llmChain.prompt.format(this.combineDocumentChain._prepInputs({\n                    [this.combineDocumentChain.inputKey]: currentDocs,\n                    ...rest,\n                }));\n                const length = await this.combineDocumentChain.llmChain._getNumTokens(formatted);\n                const withinTokenLimit = length < this.maxTokens;\n                // If we can skip the map step, and we're within the token limit, we don't\n                // need to run the map step, so just break out of the loop.\n                if (withinTokenLimit) {\n                    break;\n                }\n            }\n            const results = await this.llmChain.apply(inputs, \n            // If we have a runManager, then we need to create a child for each input\n            // so that we can track the progress of each input.\n            runManager\n                ? Array.from({ length: inputs.length }, (_, i) => runManager.getChild(`map_${i + 1}`))\n                : undefined);\n            const { outputKey } = this.llmChain;\n            // If the flag is set, then concat that to the intermediate steps\n            if (this.returnIntermediateSteps) {\n                intermediateSteps = intermediateSteps.concat(results.map((r) => r[outputKey]));\n            }\n            currentDocs = results.map((r) => ({\n                pageContent: r[outputKey],\n                metadata: {},\n            }));\n        }\n        // Now, with the final result of all the inputs from the `llmChain`, we can\n        // run the `combineDocumentChain` over them.\n        const newInputs = {\n            [this.combineDocumentChain.inputKey]: currentDocs,\n            ...rest,\n        };\n        const result = await this.combineDocumentChain.call(newInputs, runManager?.getChild(\"combine_documents\"));\n        // Return the intermediate steps results if the flag is set\n        if (this.returnIntermediateSteps) {\n            return { ...result, intermediateSteps };\n        }\n        return result;\n    }\n    _chainType() {\n        return \"map_reduce_documents_chain\";\n    }\n    static async deserialize(data) {\n        if (!data.llm_chain) {\n            throw new Error(\"Missing llm_chain\");\n        }\n        if (!data.combine_document_chain) {\n            throw new Error(\"Missing combine_document_chain\");\n        }\n        return new MapReduceDocumentsChain({\n            llmChain: await LLMChain.deserialize(data.llm_chain),\n            combineDocumentChain: await StuffDocumentsChain.deserialize(data.combine_document_chain),\n        });\n    }\n    serialize() {\n        return {\n            _type: this._chainType(),\n            llm_chain: this.llmChain.serialize(),\n            combine_document_chain: this.combineDocumentChain.serialize(),\n        };\n    }\n}\n/**\n * Combine documents by doing a first pass and then refining on more documents.\n * @augments BaseChain\n * @augments RefineDocumentsChainInput\n */\nexport class RefineDocumentsChain extends BaseChain {\n    static lc_name() {\n        return \"RefineDocumentsChain\";\n    }\n    get defaultDocumentPrompt() {\n        return new PromptTemplate({\n            inputVariables: [\"page_content\"],\n            template: \"{page_content}\",\n        });\n    }\n    get inputKeys() {\n        return [\n            ...new Set([\n                this.inputKey,\n                ...this.llmChain.inputKeys,\n                ...this.refineLLMChain.inputKeys,\n            ]),\n        ].filter((key) => key !== this.documentVariableName && key !== this.initialResponseName);\n    }\n    get outputKeys() {\n        return [this.outputKey];\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"llmChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"inputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"input_documents\"\n        });\n        Object.defineProperty(this, \"outputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"output_text\"\n        });\n        Object.defineProperty(this, \"documentVariableName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"context\"\n        });\n        Object.defineProperty(this, \"initialResponseName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"existing_answer\"\n        });\n        Object.defineProperty(this, \"refineLLMChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"documentPrompt\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: this.defaultDocumentPrompt\n        });\n        this.llmChain = fields.llmChain;\n        this.refineLLMChain = fields.refineLLMChain;\n        this.documentVariableName =\n            fields.documentVariableName ?? this.documentVariableName;\n        this.inputKey = fields.inputKey ?? this.inputKey;\n        this.outputKey = fields.outputKey ?? this.outputKey;\n        this.documentPrompt = fields.documentPrompt ?? this.documentPrompt;\n        this.initialResponseName =\n            fields.initialResponseName ?? this.initialResponseName;\n    }\n    /** @ignore */\n    async _constructInitialInputs(doc, rest) {\n        const baseInfo = {\n            page_content: doc.pageContent,\n            ...doc.metadata,\n        };\n        const documentInfo = {};\n        this.documentPrompt.inputVariables.forEach((value) => {\n            documentInfo[value] = baseInfo[value];\n        });\n        const baseInputs = {\n            [this.documentVariableName]: await this.documentPrompt.format({\n                ...documentInfo,\n            }),\n        };\n        const inputs = { ...baseInputs, ...rest };\n        return inputs;\n    }\n    /** @ignore */\n    async _constructRefineInputs(doc, res) {\n        const baseInfo = {\n            page_content: doc.pageContent,\n            ...doc.metadata,\n        };\n        const documentInfo = {};\n        this.documentPrompt.inputVariables.forEach((value) => {\n            documentInfo[value] = baseInfo[value];\n        });\n        const baseInputs = {\n            [this.documentVariableName]: await this.documentPrompt.format({\n                ...documentInfo,\n            }),\n        };\n        const inputs = { [this.initialResponseName]: res, ...baseInputs };\n        return inputs;\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        if (!(this.inputKey in values)) {\n            throw new Error(`Document key ${this.inputKey} not found.`);\n        }\n        const { [this.inputKey]: docs, ...rest } = values;\n        const currentDocs = docs;\n        const initialInputs = await this._constructInitialInputs(currentDocs[0], rest);\n        let res = await this.llmChain.predict({ ...initialInputs }, runManager?.getChild(\"answer\"));\n        const refineSteps = [res];\n        for (let i = 1; i < currentDocs.length; i += 1) {\n            const refineInputs = await this._constructRefineInputs(currentDocs[i], res);\n            const inputs = { ...refineInputs, ...rest };\n            res = await this.refineLLMChain.predict({ ...inputs }, runManager?.getChild(\"refine\"));\n            refineSteps.push(res);\n        }\n        return { [this.outputKey]: res };\n    }\n    _chainType() {\n        return \"refine_documents_chain\";\n    }\n    static async deserialize(data) {\n        const SerializedLLMChain = data.llm_chain;\n        if (!SerializedLLMChain) {\n            throw new Error(\"Missing llm_chain\");\n        }\n        const SerializedRefineDocumentChain = data.refine_llm_chain;\n        if (!SerializedRefineDocumentChain) {\n            throw new Error(\"Missing refine_llm_chain\");\n        }\n        return new RefineDocumentsChain({\n            llmChain: await LLMChain.deserialize(SerializedLLMChain),\n            refineLLMChain: await LLMChain.deserialize(SerializedRefineDocumentChain),\n        });\n    }\n    serialize() {\n        return {\n            _type: this._chainType(),\n            llm_chain: this.llmChain.serialize(),\n            refine_llm_chain: this.refineLLMChain.serialize(),\n        };\n    }\n}\n","import { Serializable } from \"../load/serializable.js\";\n/**\n * Base class for example selectors.\n */\nexport class BaseExampleSelector extends Serializable {\n    constructor() {\n        super(...arguments);\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain_core\", \"example_selectors\", \"base\"]\n        });\n    }\n}\n","/**\n * Abstract class that defines the interface for selecting a prompt for a\n * given language model.\n */\nexport class BasePromptSelector {\n    /**\n     * Asynchronous version of `getPrompt` that also accepts an options object\n     * for partial variables.\n     * @param llm The language model for which to get a prompt.\n     * @param options Optional object for partial variables.\n     * @returns A Promise that resolves to a prompt template.\n     */\n    async getPromptAsync(llm, options) {\n        const prompt = this.getPrompt(llm);\n        return prompt.partial(options?.partialVariables ?? {});\n    }\n}\n/**\n * Concrete implementation of `BasePromptSelector` that selects a prompt\n * based on a set of conditions. It has a default prompt that it returns\n * if none of the conditions are met.\n */\nexport class ConditionalPromptSelector extends BasePromptSelector {\n    constructor(default_prompt, conditionals = []) {\n        super();\n        Object.defineProperty(this, \"defaultPrompt\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"conditionals\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.defaultPrompt = default_prompt;\n        this.conditionals = conditionals;\n    }\n    /**\n     * Method that selects a prompt based on a set of conditions. If none of\n     * the conditions are met, it returns the default prompt.\n     * @param llm The language model for which to get a prompt.\n     * @returns A prompt template.\n     */\n    getPrompt(llm) {\n        for (const [condition, prompt] of this.conditionals) {\n            if (condition(llm)) {\n                return prompt;\n            }\n        }\n        return this.defaultPrompt;\n    }\n}\n/**\n * Type guard function that checks if a given language model is of type\n * `BaseLLM`.\n */\nexport function isLLM(llm) {\n    return llm._modelType() === \"base_llm\";\n}\n/**\n * Type guard function that checks if a given language model is of type\n * `BaseChatModel`.\n */\nexport function isChatModel(llm) {\n    return llm._modelType() === \"base_chat_model\";\n}\n","/* eslint-disable spaced-comment */\nimport { ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate, } from \"@langchain/core/prompts\";\nimport { ConditionalPromptSelector, isChatModel, } from \"@langchain/core/example_selectors\";\nexport const DEFAULT_QA_PROMPT = /*#__PURE__*/ new PromptTemplate({\n    template: \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\",\n    inputVariables: [\"context\", \"question\"],\n});\nconst system_template = `Use the following pieces of context to answer the users question. \nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\n----------------\n{context}`;\nconst messages = [\n    /*#__PURE__*/ SystemMessagePromptTemplate.fromTemplate(system_template),\n    /*#__PURE__*/ HumanMessagePromptTemplate.fromTemplate(\"{question}\"),\n];\nconst CHAT_PROMPT = /*#__PURE__*/ ChatPromptTemplate.fromMessages(messages);\nexport const QA_PROMPT_SELECTOR = /*#__PURE__*/ new ConditionalPromptSelector(DEFAULT_QA_PROMPT, [[isChatModel, CHAT_PROMPT]]);\n","import { LLMChain } from \"../llm_chain.js\";\nimport { StuffDocumentsChain, MapReduceDocumentsChain, RefineDocumentsChain, } from \"../combine_docs_chain.js\";\nimport { QA_PROMPT_SELECTOR } from \"./stuff_prompts.js\";\nimport { COMBINE_PROMPT_SELECTOR, COMBINE_QA_PROMPT_SELECTOR, } from \"./map_reduce_prompts.js\";\nimport { QUESTION_PROMPT_SELECTOR, REFINE_PROMPT_SELECTOR, } from \"./refine_prompts.js\";\nexport const loadQAChain = (llm, params = { type: \"stuff\" }) => {\n    const { type } = params;\n    if (type === \"stuff\") {\n        return loadQAStuffChain(llm, params);\n    }\n    if (type === \"map_reduce\") {\n        return loadQAMapReduceChain(llm, params);\n    }\n    if (type === \"refine\") {\n        return loadQARefineChain(llm, params);\n    }\n    throw new Error(`Invalid _type: ${type}`);\n};\n/**\n * Loads a StuffQAChain based on the provided parameters. It takes an LLM\n * instance and StuffQAChainParams as parameters.\n * @param llm An instance of BaseLanguageModel.\n * @param params Parameters for creating a StuffQAChain.\n * @returns A StuffQAChain instance.\n */\nexport function loadQAStuffChain(llm, params = {}) {\n    const { prompt = QA_PROMPT_SELECTOR.getPrompt(llm), verbose } = params;\n    const llmChain = new LLMChain({ prompt, llm, verbose });\n    const chain = new StuffDocumentsChain({ llmChain, verbose });\n    return chain;\n}\n/**\n * Loads a MapReduceQAChain based on the provided parameters. It takes an\n * LLM instance and MapReduceQAChainParams as parameters.\n * @param llm An instance of BaseLanguageModel.\n * @param params Parameters for creating a MapReduceQAChain.\n * @returns A MapReduceQAChain instance.\n */\nexport function loadQAMapReduceChain(llm, params = {}) {\n    const { combineMapPrompt = COMBINE_QA_PROMPT_SELECTOR.getPrompt(llm), combinePrompt = COMBINE_PROMPT_SELECTOR.getPrompt(llm), verbose, combineLLM, returnIntermediateSteps, } = params;\n    const llmChain = new LLMChain({ prompt: combineMapPrompt, llm, verbose });\n    const combineLLMChain = new LLMChain({\n        prompt: combinePrompt,\n        llm: combineLLM ?? llm,\n        verbose,\n    });\n    const combineDocumentChain = new StuffDocumentsChain({\n        llmChain: combineLLMChain,\n        documentVariableName: \"summaries\",\n        verbose,\n    });\n    const chain = new MapReduceDocumentsChain({\n        llmChain,\n        combineDocumentChain,\n        returnIntermediateSteps,\n        verbose,\n    });\n    return chain;\n}\n/**\n * Loads a RefineQAChain based on the provided parameters. It takes an LLM\n * instance and RefineQAChainParams as parameters.\n * @param llm An instance of BaseLanguageModel.\n * @param params Parameters for creating a RefineQAChain.\n * @returns A RefineQAChain instance.\n */\nexport function loadQARefineChain(llm, params = {}) {\n    const { questionPrompt = QUESTION_PROMPT_SELECTOR.getPrompt(llm), refinePrompt = REFINE_PROMPT_SELECTOR.getPrompt(llm), refineLLM, verbose, } = params;\n    const llmChain = new LLMChain({ prompt: questionPrompt, llm, verbose });\n    const refineLLMChain = new LLMChain({\n        prompt: refinePrompt,\n        llm: refineLLM ?? llm,\n        verbose,\n    });\n    const chain = new RefineDocumentsChain({\n        llmChain,\n        refineLLMChain,\n        verbose,\n    });\n    return chain;\n}\n","import { BaseChain } from \"./base.js\";\nimport { loadQAStuffChain } from \"./question_answering/load.js\";\n/**\n * Class that represents a VectorDBQAChain. It extends the `BaseChain`\n * class and implements the `VectorDBQAChainInput` interface. It performs\n * a similarity search using a vector store and combines the search\n * results using a specified combine documents chain.\n *\n * @deprecated\n * Switch to {@link https://js.langchain.com/docs/modules/chains/ | createRetrievalChain}\n * Will be removed in 0.2.0\n */\nexport class VectorDBQAChain extends BaseChain {\n    static lc_name() {\n        return \"VectorDBQAChain\";\n    }\n    get inputKeys() {\n        return [this.inputKey];\n    }\n    get outputKeys() {\n        return this.combineDocumentsChain.outputKeys.concat(this.returnSourceDocuments ? [\"sourceDocuments\"] : []);\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"k\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 4\n        });\n        Object.defineProperty(this, \"inputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"query\"\n        });\n        Object.defineProperty(this, \"vectorstore\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"combineDocumentsChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"returnSourceDocuments\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        this.vectorstore = fields.vectorstore;\n        this.combineDocumentsChain = fields.combineDocumentsChain;\n        this.inputKey = fields.inputKey ?? this.inputKey;\n        this.k = fields.k ?? this.k;\n        this.returnSourceDocuments =\n            fields.returnSourceDocuments ?? this.returnSourceDocuments;\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        if (!(this.inputKey in values)) {\n            throw new Error(`Question key ${this.inputKey} not found.`);\n        }\n        const question = values[this.inputKey];\n        const docs = await this.vectorstore.similaritySearch(question, this.k, values.filter, runManager?.getChild(\"vectorstore\"));\n        const inputs = { question, input_documents: docs };\n        const result = await this.combineDocumentsChain.call(inputs, runManager?.getChild(\"combine_documents\"));\n        if (this.returnSourceDocuments) {\n            return {\n                ...result,\n                sourceDocuments: docs,\n            };\n        }\n        return result;\n    }\n    _chainType() {\n        return \"vector_db_qa\";\n    }\n    static async deserialize(data, values) {\n        if (!(\"vectorstore\" in values)) {\n            throw new Error(`Need to pass in a vectorstore to deserialize VectorDBQAChain`);\n        }\n        const { vectorstore } = values;\n        if (!data.combine_documents_chain) {\n            throw new Error(`VectorDBQAChain must have combine_documents_chain in serialized data`);\n        }\n        return new VectorDBQAChain({\n            combineDocumentsChain: await BaseChain.deserialize(data.combine_documents_chain),\n            k: data.k,\n            vectorstore,\n        });\n    }\n    serialize() {\n        return {\n            _type: this._chainType(),\n            combine_documents_chain: this.combineDocumentsChain.serialize(),\n            k: this.k,\n        };\n    }\n    /**\n     * Static method that creates a VectorDBQAChain instance from a\n     * BaseLanguageModel and a vector store. It also accepts optional options\n     * to customize the chain.\n     * @param llm The BaseLanguageModel instance.\n     * @param vectorstore The vector store used for similarity search.\n     * @param options Optional options to customize the chain.\n     * @returns A new instance of VectorDBQAChain.\n     */\n    static fromLLM(llm, vectorstore, options) {\n        const qaChain = loadQAStuffChain(llm);\n        return new this({\n            vectorstore,\n            combineDocumentsChain: qaChain,\n            ...options,\n        });\n    }\n}\n"],"names":["StuffDocumentsChain","lc_name","inputKeys","this","inputKey","llmChain","filter","key","documentVariableName","outputKeys","constructor","fields","super","Object","defineProperty","enumerable","configurable","writable","value","_prepInputs","values","Error","docs","rest","texts","map","pageContent","text","join","_call","runManager","result","call","getChild","_chainType","deserialize","data","llm_chain","LLMChain","serialize","_type","MapReduceDocumentsChain","combineDocumentChain","ensureMapStep","maxTokens","maxIterations","returnIntermediateSteps","currentDocs","intermediateSteps","i","inputs","d","canSkipMapStep","formatted","prompt","format","length","_getNumTokens","withinTokenLimit","results","apply","Array","from","_","undefined","outputKey","concat","r","metadata","newInputs","combine_document_chain","RefineDocumentsChain","defaultDocumentPrompt","inputVariables","template","Set","refineLLMChain","initialResponseName","documentPrompt","_constructInitialInputs","doc","baseInfo","page_content","documentInfo","forEach","baseInputs","_constructRefineInputs","res","initialInputs","predict","refineSteps","refineInputs","push","SerializedLLMChain","SerializedRefineDocumentChain","refine_llm_chain","BasePromptSelector","getPromptAsync","llm","options","getPrompt","partial","partialVariables","ConditionalPromptSelector","default_prompt","conditionals","defaultPrompt","condition","isChatModel","_modelType","DEFAULT_QA_PROMPT","system_template","messages","fromTemplate","CHAT_PROMPT","fromMessages","QA_PROMPT_SELECTOR","loadQAStuffChain","params","verbose","chain","VectorDBQAChain","combineDocumentsChain","returnSourceDocuments","vectorstore","k","question","similaritySearch","input_documents","sourceDocuments","combine_documents_chain","fromLLM","qaChain"],"sourceRoot":""}